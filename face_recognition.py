# -*- coding: utf-8 -*-
"""face_recognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OINAx01ztL0LoDoR0U3ixTgkDDTRc_ce
"""

#header files
from __future__ import absolute_import, division, print_function, unicode_literals
import tensorflow as tf
import pandas as pd 
import numpy as np

import keras_vggface
#vggFace
from keras_vggface.vggface import VGGFace

import keras
#model layers
from keras.models import Model, Sequential
from keras.layers import Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Flatten, Dense, Dropout, Activation

#processing and optimizer header
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import SGD

import matplotlib
#matplotlib
import matplotlib.pyplot as plt

#header files for preprocessing of image we want to recognize
from keras.models import load_model
from keras.preprocessing.image import load_img, save_img, img_to_array
from keras_vggface.utils import preprocess_input

#versions

print("TensorFlow Version:",tf.__version__)
print("Keras Version:",keras.__version__)
print("Keras-VGGface Version:",keras_vggface.__version__)
print("Matplotlib Version:",matplotlib.__version__)
print("Numpy Version:",np.__version__)
print("Pandas Version:",pd.__version__)

#loading the pretrained model VGG16
  
pre_trained_model=VGGFace(input_shape=(224, 224, 3),model='vgg16',weights='vggface',include_top=False)

print("[OUT]: The model Summary befor making layers non-trainable")
print(pre_trained_model.summary())

#making layers non trainable
for layer in pre_trained_model.layers:
    layer.trainable = False

print("[OUT]:Summary after making layers non-trainable.")
print(pre_trained_model.summary())

#since we  need to recognize total 6 faces (me + 5 others)
total_person=6
model_last_layer = pre_trained_model.get_layer('pool5').output

#now we need to define our own final layers for recognition

custom_layer=Flatten(name='Flatten')(model_last_layer)
custom_layer=Dense(1024,activation='relu',name="custom_fc6")(custom_layer)
custom_layer=Dense(1024,activation='relu',name="custom_fc7")(custom_layer)
final_output=Dense(total_person,activation='softmax',name="final_6person_fc8")(custom_layer)

#final_model
custom_final_model=Model(pre_trained_model.input,final_output)

print("[OUT]: Final Custom model Summary:")
print(custom_final_model.summary())

#processing image and generating more  data from images

batch_size = 5
train_data_path = '/Data/train/'
test_data_path = '/Data/test/'

train_data_generator = ImageDataGenerator(rescale=1.0/255.0,horizontal_flip=True,shear_range=0.2,zoom_range=0.2)

test_data_generator = ImageDataGenerator(rescale=1.0/255.0,horizontal_flip=True,shear_range=0.2,zoom_range=0.2)

train_data = train_data_generator.flow_from_directory(directory=train_data_path,target_size=(224,224),
                                                      batch_size=batch_size,class_mode='sparse',color_mode='rgb',shuffle=True)

test_data =  test_data_generator.flow_from_directory(directory=test_data_path,target_size=(224,224),
                                                      batch_size=batch_size,class_mode='sparse',color_mode='rgb')

#compiling model
custom_final_model.compile(loss='sparse_categorical_crossentropy',optimizer=SGD(lr=1e-4, momentum=0.9),metrics=['accuracy'])

#training model on generated data

model_history = custom_final_model.fit_generator(train_data,validation_data=test_data,steps_per_epoch=50/batch_size,
                                          validation_steps=test_data.n,epochs=50)

custom_final_model.evaluate_generator(generator=test_data)

#saving model
custom_final_model.save('/Data/Custom_6_face_reco.h5')

#plotting training and validation accuracy and loss

acc = model_history.history['acc']
val_acc = model_history.history['val_acc']

loss = model_history.history['loss']
val_loss = model_history.history['val_loss']

#training and validation accuracy 
plt.figure(figsize=(10,10))
plt.subplot(2, 1, 1)
plt.plot(acc, label='Training Accuracy')
plt.plot(val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.ylabel('Accuracy')
plt.title('Custom Model: Training and Validation Accuracy')

#training and validation accuracy 
plt.subplot(2, 1, 2)
plt.plot(loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.ylabel('Cross Entropy')
plt.title('Custom Model Training and Validation Loss')
plt.xlabel('epoch')
plt.show()

#my image after converting to  size 224*224

test1_img = load_img('/Data/Prediction_Images/Test_1.jpg',target_size=(224, 224))

plt.imshow(test1_img)

#preprocess image
img = img_to_array(test1_img)
img = np.expand_dims(img, axis=0)
img = preprocess_input(img)

#prediction using custom model 
all_predictions = custom_final_model.predict(img)
predicted_class=np.argmax(all_predictions,axis=1)

#getting labels
labels = (train_data.class_indices)
labels = dict((indx,lab) for lab,indx in labels.items())
predictions = [labels[indx] for indx in predicted_class]

#show label after predictions


print("[OUT]:The person in the image is : ",predictions)

#Dwayne Johnson(The Rock) Image after converting to  size 224*224

test2_img = load_img('/Data/Prediction_Images/Test_2.jpg',target_size=(224, 224))

plt.imshow(test2_img)

#preprocess image
img = img_to_array(test2_img)
img = np.expand_dims(img, axis=0)
img = preprocess_input(img)

#prediction using custom model 
all_predictions = custom_final_model.predict(img)
predicted_class=np.argmax(all_predictions,axis=1)

#getting labels
labels = (train_data.class_indices)
labels = dict((indx,lab) for lab,indx in labels.items())
predictions = [labels[indx] for indx in predicted_class]

#show label after predictions


print("[OUT]:The person in the image is : ",predictions)

#Robert Downey Image after converting to  size 224*224

test3_img = load_img('/Data/Prediction_Images/Test_3.jpg',target_size=(224, 224))

plt.imshow(test3_img)

#preprocess image
img = img_to_array(test3_img)
img = np.expand_dims(img, axis=0)
img = preprocess_input(img)

#prediction using custom model 
all_predictions = custom_final_model.predict(img)
predicted_class=np.argmax(all_predictions,axis=1)

#getting labels
labels = (train_data.class_indices)
labels = dict((indx,lab) for lab,indx in labels.items())
predictions = [labels[indx] for indx in predicted_class]

#show label after predictions


print("[OUT]:The person in the image is : ",predictions)

#Christian Bale : Image after converting to  size 224*224

test4_img = load_img('/Data/Prediction_Images/Test_4.jpg',target_size=(224, 224))

plt.imshow(test4_img)

#preprocess image
img = img_to_array(test4_img)
img = np.expand_dims(img, axis=0)
img = preprocess_input(img)

#prediction using custom model 
all_predictions = custom_final_model.predict(img)
predicted_class=np.argmax(all_predictions,axis=1)

#getting labels
labels = (train_data.class_indices)
labels = dict((indx,lab) for lab,indx in labels.items())
predictions = [labels[indx] for indx in predicted_class]

#show label after predictions


print("[OUT]:The person in the image is : ",predictions)

#Bill Gates : Image after converting to  size 224*224

test5_img = load_img('/Data/Prediction_Images/Test_5.jpg',target_size=(224, 224))

plt.imshow(test5_img)

#preprocess image
img = img_to_array(test5_img)
img = np.expand_dims(img, axis=0)
img = preprocess_input(img)

#prediction using custom model 
all_predictions = custom_final_model.predict(img)
predicted_class=np.argmax(all_predictions,axis=1)

#getting labels
labels = (train_data.class_indices)
labels = dict((indx,lab) for lab,indx in labels.items())
predictions = [labels[indx] for indx in predicted_class]

#show label after predictions


print("[OUT]:The person in the image is : ",predictions)

#Hrithik Roshan: Image after converting to  size 224*224

test6_img = load_img('/Data/Prediction_Images/Test_6.jpg',target_size=(224, 224))

plt.imshow(test6_img)

#preprocess image
img = img_to_array(test6_img)
img = np.expand_dims(img, axis=0)
img = preprocess_input(img)

#prediction using custom model 
all_predictions = custom_final_model.predict(img)
predicted_class=np.argmax(all_predictions,axis=1)

#getting labels
labels = (train_data.class_indices)
labels = dict((indx,lab) for lab,indx in labels.items())
predictions = [labels[indx] for indx in predicted_class]

#show label after predictions


print("[OUT]:The person in the image is : ",predictions)